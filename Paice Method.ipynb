{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paice method for evaluation of Stemmer\n",
    "\n",
    "## Stemming\n",
    "Stemming of a word essentially means to remove all linguistic inflections present in the word and transform it into a simple *word stem*. This is usually done to improve recall in an IR system (think search engine) and also for removing noises while constructing statistical models like *Bag of Words*. For example, the words *walking, walked,* and *walks* are all variations of the verb *walk*. In the context of a search engine, it is desirable to fetch all the documents containing these terms when the input query is *walk*.\n",
    "\n",
    "Stemming is usually done by stripping off suffixes and prefixes from words. If we are to consider a simple stemmer which strips only the suffixes *-ing, -ed,* and *-s*, then the words can be stemmed as follows:\n",
    "\n",
    "* walking -> walk\n",
    "* walked -> walk\n",
    "* walks -> walk\n",
    "* walk -> walk\n",
    "\n",
    "The above example can be a bit misleading because stemming does not need to produce a grammatically correct word. Consider the words *tasted* and *tasting*. When stemmed by stripping the suffixes described above, these words become:\n",
    "\n",
    "* tasted -> tast\n",
    "* tasting -> tast\n",
    "\n",
    "This is not necessarily incorrect. All that is required of a stemmer is that it conflate the related inflections to a single stem even if the stem is not a grammatically valid word. But consider the word *taste* which, when stemmed, remains *taste* i.e. it has different stem than *tasted* and *tasting* even though all three of them are related. This is an error. A *under-stemming* error to be precise.\n",
    "\n",
    "<img src=\"images/stem_walk.png\"></img>\n",
    "\n",
    "## Evaluating Stemmers\n",
    "\n",
    "Suppose you write a stemming scheme and also implement it in a programming language of your choice. How do you then evaluate just how good your stemmer is? That is to say, how do you know how your stemmer fares against any other stemmer. What is needed is a quantifying metric which could assess the goodness of your implementation. There are a few ways one could go about it.\n",
    "\n",
    "### Error rate calculation\n",
    "\n",
    "One way of evaluating stemmers would be to manually construct a dataset consisting of a word and its corresponding stem. For instance, one entry in such a dataset would be *`<walking, walk>`*. *Walking* being the word and *walk* being the desired stem. The evaluation is then done by stemming all the words and checking if the stem produced does indeed match up with the stem provided in the dataset. For example, consider the dataset to have these four entries.\n",
    "\n",
    "1. `<walking, walk>`\n",
    "2. `<walked, walk>`\n",
    "3. `<tasting, tast>`\n",
    "4. `<taste, tast>`\n",
    "\n",
    "When the stemmer from before is run on the dataset, the results obtained would be:\n",
    "\n",
    "1. `<walking, walk>`\n",
    "2. `<walked, walk>`\n",
    "3. `<tasting, tast>`\n",
    "4. `<taste, taste>`\n",
    "\n",
    "Clearly, output of the fourth entry doesn't match up with the one in the dataset. Hence, one word out of four was stemmed incorrectly; the error then would be $$\\frac 1 4 = 25\\%$$\n",
    "\n",
    "This method has the advantage that it is easily implemented. One need only provide the list of manually paired word and its stem. This method, however, is fundamentally flawed. The testing is done by comparing the output of the stemmer to the correct stem. *But there is no such thing as a correct stem*. A stemmer can very well conflate the word *walking* to the stem *wal* and it would be correct so long as it also conflates other inflections (*walked* and *walk*) to the same.\n",
    "\n",
    "### Over-Stemming vs Under-Stemming calculation\n",
    "\n",
    "Two very useful metrics to quantify a stemmer with are the over and under stemming errors. Under-stemming is when two related words do not reduce to the same stem. We saw that using the previous stemmer, the word *tasting* conflated to the stem *tast* whereas the word *taste* conflated to the stem *taste*. The two words are related inflections but the stemmer doesn't reduce the two to the same.\n",
    "\n",
    "Similarly, consider the words *red* and *ring*. These two are totally unrelated words. However, using our stemmer, these two are conflated to the same stem i.e. *r*. This is over-stemming i.e. reducing two unrelated words into a same stem.\n",
    "\n",
    "### Paice's Method\n",
    "\n",
    "Counting over-stemming and under-stemming errors seems to be a very useful evaluation scheme for stemmers. After all, this method doesn't need the concept of a correct stem and instead only requires that two related words conflate to a same stem and two unrelated words to different. This is precisely what Paice's method does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
